{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=150 src=https://raw.githubusercontent.com/autonomio/signs/master/logo.png><center><font size=3>Signs is a set of tools for text preparation, vectorization and processing. Below is provided a set of examples that cover many of the commonly used workflows. </font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signs as signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning | `signs.Clean()`\n",
    "\n",
    "While `signs.Transform()` has `auto=True` for automatic cleaning, sometimes it's useful to explicitly clean documents. Let's start with an automated example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ' Jack is a green  ðŸ˜‚ðŸ˜‚ðŸ˜‚ cat... \\n with a hat \\n  '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the object\n",
    "cleaned = signs.Clean(doc)\n",
    "\n",
    "# access the text\n",
    "cleaned.text\n",
    "\n",
    "# you could of course also directly do\n",
    "signs.Clean(doc).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the cleaning operations can be accessed individually, and not all cleaning operations are included in the automatic processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the object\n",
    "cleaned = signs.Clean(doc, auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make text all caps\n",
    "cleaned.caps()\n",
    "\n",
    "# make text all lower\n",
    "cleaned.low()\n",
    "\n",
    "# decode the text\n",
    "cleaned.decod()\n",
    "\n",
    "# remove emojis\n",
    "cleaned.emoji()\n",
    "\n",
    "# remove leading and trailing whitespace\n",
    "cleaned.leadtrail()\n",
    "\n",
    "# remove all whitespace\n",
    "cleaned.whitespace()\n",
    "\n",
    "# remove linebreaks\n",
    "cleaned.linebreaks()\n",
    "\n",
    "# remove links\n",
    "cleaned.links()\n",
    "\n",
    "# remove punctuation\n",
    "cleaned.punct()\n",
    "\n",
    "# remove arbitrary string\n",
    "cleaned.string('is a green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove common words | `signs.Stopwords()`\n",
    "\n",
    "**Signs** another common operation for data cleaning involves removing a list of words from the documents. \n",
    "\n",
    "For this purpose we have to transform the documents into a list-of-lists where each sublist consist of a tokenized document. This easily done with `signs.Transform()`. Because `signs.Transform()` expects as input a set of documents, and only have one, we have to wrap the document in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform doc/s to the right format\n",
    "tokens = signs.Transform([doc]).tokens()\n",
    "\n",
    "# filter the docs\n",
    "filtered_tokens = signs.Stopwords(tokens)\n",
    "\n",
    "# then access the filtered docs\n",
    "filtered_tokens.docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`signs.Stopwords()` allows several options for customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set minimum length for words\n",
    "signs.Stopwords(tokens, min_length=3)\n",
    "\n",
    "# set maximum threshold for words (accept all words above this)\n",
    "signs.Stopwords(tokens, max_threshold=8)\n",
    "\n",
    "# add custom words\n",
    "signs.Stopwords(tokens, add_stopwords=['jack'])\n",
    "\n",
    "# just use custom words\n",
    "signs.Stopwords(tokens, common_stopwords=False, add_stopwords=['jack']).docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bare in mind that all operations in `signs.Stopwords()` are destructive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
